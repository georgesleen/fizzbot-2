run:
  # Device selection: auto | cpu | cuda.
  device: auto
  # Base directory containing timestamped runs for --latest.
  runs_dir: runs/fizzbot
  # Default model for CPU inference (model id or local path).
  cpu_model: microsoft/phi-2
  # Default model for CUDA inference (model id or local path).
  gpu_model: mistralai/Mistral-7B-Instruct-v0.2
  # Sampling controls.
  # Maximum number of tokens to generate.
  max_new_tokens: 120
  # Sampling temperature (higher = more random).
  temperature: 0.8
  # Nucleus sampling probability.
  top_p: 0.9
  # RNG seed (0 disables seeding).
  seed: 0
